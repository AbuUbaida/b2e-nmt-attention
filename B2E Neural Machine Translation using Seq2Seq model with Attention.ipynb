{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"16L47i7pmmcERgdnFCBl2zHTMPJwFno9o","authorship_tag":"ABX9TyMOYYiufETMk740lEjnfjrF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"rNiut4EwHBFs","executionInfo":{"status":"ok","timestamp":1663397612413,"user_tz":-360,"elapsed":3994,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"outputs":[],"source":["%%capture\n","!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl \n","!pip3 install torchvision"]},{"cell_type":"code","source":["import torch\n","import torch.functional as F\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import unicodedata\n","import re\n","import time\n","\n","print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtUkepnIHOQR","executionInfo":{"status":"ok","timestamp":1663396365947,"user_tz":-360,"elapsed":2250,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}},"outputId":"288b7078-af27-48c2-e1ff-3ac8af9a3889"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["1.12.1+cu113\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')"],"metadata":{"id":"DYc1P_Z-HZbH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f = open('/content/drive/MyDrive/Projects/B2E Neural Machine Translation using Seq2Seq model with Attention/data/ben.txt', encoding='UTF-8').read().strip().split('\\n')\n","lines = f"],"metadata":{"id":"geDU5YtaH6uP","executionInfo":{"status":"ok","timestamp":1663396390953,"user_tz":-360,"elapsed":2631,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["num_examples = 4642 \n","\n","# creates lists containing each pair\n","original_word_pairs = [[w for w in l.split('\\t')] for l in lines[:num_examples]]"],"metadata":{"id":"u8xv_y6EII88","executionInfo":{"status":"ok","timestamp":1663396391699,"user_tz":-360,"elapsed":749,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["data = pd.DataFrame(original_word_pairs, columns=[\"en\", \"bn\", \"extra\"])\n","data = data.drop([\"extra\"], axis=1)\n","data.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"DrFhYmWAIab-","executionInfo":{"status":"ok","timestamp":1663396391700,"user_tz":-360,"elapsed":6,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}},"outputId":"c446a95f-5e62-45e2-b19a-ac3f753ce38d"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     en      bn\n","0   Go.    যাও।\n","1   Go.    যান।\n","2   Go.     যা।\n","3  Run!  পালাও!\n","4  Run!  পালান!"],"text/html":["\n","  <div id=\"df-70c03a41-0ada-4b39-90a3-ea43dd661491\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>en</th>\n","      <th>bn</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>যাও।</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Go.</td>\n","      <td>যান।</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Go.</td>\n","      <td>যা।</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>পালাও!</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Run!</td>\n","      <td>পালান!</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70c03a41-0ada-4b39-90a3-ea43dd661491')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-70c03a41-0ada-4b39-90a3-ea43dd661491 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-70c03a41-0ada-4b39-90a3-ea43dd661491');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"913VSLih4lY3","executionInfo":{"status":"ok","timestamp":1663396391700,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"source":["# Converts the unicode file to ascii\n","def unicode_to_ascii(s):\n","    \"\"\"\n","    Normalizes latin chars with accent to their canonical decomposition\n","    \"\"\"\n","    return ''.join(c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn')\n","\n","def preprocess_sentence(w):\n","    w = unicode_to_ascii(w.lower().strip())\n","    \n","    # creating a space between a word and the punctuation following it\n","    # eg: \"he is a boy.\" => \"he is a boy .\" \n","    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n","    w = re.sub(r\"([?.!,¿।,])\", r\" \\1 \", w)\n","    w = re.sub(r'[\" \"]+', \" \", w)\n","    \n","    w = w.rstrip().strip()\n","    \n","    # adding a start and an end token to the sentence\n","    # so that the model know when to start and stop predicting.\n","    w = '<start> ' + w + ' <end>'\n","    return w"],"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Now we do the preprocessing using pandas and lambdas\n","data[\"en\"] = data.en.apply(lambda w: preprocess_sentence(w))\n","data[\"bn\"] = data.bn.apply(lambda w: preprocess_sentence(w))\n","data.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"DZHqSJ17J_sM","executionInfo":{"status":"ok","timestamp":1663396396711,"user_tz":-360,"elapsed":794,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}},"outputId":"465b1aa6-7b3c-471c-af01-4a6ee98eb1ea"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                     en  \\\n","3328         <start> what are you talking about ? <end>   \n","1777                  <start> everyone screamed . <end>   \n","1167                     <start> tom was inside . <end>   \n","581                          <start> we'll work . <end>   \n","2680             <start> i don't agree with him . <end>   \n","3913    <start> how much does it cost to get in ? <end>   \n","2353               <start> my motorcycle is new . <end>   \n","460                          <start> forget him . <end>   \n","4544  <start> just staying alive in these times is h...   \n","256                            <start> try hard . <end>   \n","\n","                                                     bn  \n","3328       <start> আপনি কিসের বযাপারে কথা বলছেন ? <end>  \n","1777                       <start> সবাই চেচালো । <end>  \n","1167                     <start> টম ভেতরে ছিলো । <end>  \n","581                      <start> আমরা কাজ করবো । <end>  \n","2680              <start> আমি ওনার সাথে একমত নই । <end>  \n","3913     <start> ভেতরে যাওযার জনয কত টাকা লাগবে ? <end>  \n","2353             <start> আমার মোটরসাইকেলটা নতন । <end>  \n","460                          <start> ওনাকে ছাডন । <end>  \n","4544  <start> এখনকার সময শধ বেচে থাকাটাও যথেষট কঠিন ...  \n","256                      <start> আরও চেষটা করো । <end>  "],"text/html":["\n","  <div id=\"df-b0556093-7901-46a5-8b00-2268724856ae\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>en</th>\n","      <th>bn</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3328</th>\n","      <td>&lt;start&gt; what are you talking about ? &lt;end&gt;</td>\n","      <td>&lt;start&gt; আপনি কিসের বযাপারে কথা বলছেন ? &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>1777</th>\n","      <td>&lt;start&gt; everyone screamed . &lt;end&gt;</td>\n","      <td>&lt;start&gt; সবাই চেচালো । &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>1167</th>\n","      <td>&lt;start&gt; tom was inside . &lt;end&gt;</td>\n","      <td>&lt;start&gt; টম ভেতরে ছিলো । &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>581</th>\n","      <td>&lt;start&gt; we'll work . &lt;end&gt;</td>\n","      <td>&lt;start&gt; আমরা কাজ করবো । &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>2680</th>\n","      <td>&lt;start&gt; i don't agree with him . &lt;end&gt;</td>\n","      <td>&lt;start&gt; আমি ওনার সাথে একমত নই । &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>3913</th>\n","      <td>&lt;start&gt; how much does it cost to get in ? &lt;end&gt;</td>\n","      <td>&lt;start&gt; ভেতরে যাওযার জনয কত টাকা লাগবে ? &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>2353</th>\n","      <td>&lt;start&gt; my motorcycle is new . &lt;end&gt;</td>\n","      <td>&lt;start&gt; আমার মোটরসাইকেলটা নতন । &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>460</th>\n","      <td>&lt;start&gt; forget him . &lt;end&gt;</td>\n","      <td>&lt;start&gt; ওনাকে ছাডন । &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>4544</th>\n","      <td>&lt;start&gt; just staying alive in these times is h...</td>\n","      <td>&lt;start&gt; এখনকার সময শধ বেচে থাকাটাও যথেষট কঠিন ...</td>\n","    </tr>\n","    <tr>\n","      <th>256</th>\n","      <td>&lt;start&gt; try hard . &lt;end&gt;</td>\n","      <td>&lt;start&gt; আরও চেষটা করো । &lt;end&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0556093-7901-46a5-8b00-2268724856ae')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b0556093-7901-46a5-8b00-2268724856ae button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b0556093-7901-46a5-8b00-2268724856ae');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n","# (e.g., 5 -> \"dad\") for each language,\n","class LanguageIndex():\n","    def __init__(self, lang):\n","        \"\"\" lang are the list of phrases from each language\"\"\"\n","        self.lang = lang\n","        self.word2idx = {}\n","        self.idx2word = {}\n","        self.vocab = set()\n","        \n","        self.create_index()\n","        \n","    def create_index(self):\n","        for phrase in self.lang:\n","            # update with individual tokens\n","            self.vocab.update(phrase.split(' '))\n","            \n","        # sort the vocab\n","        self.vocab = sorted(self.vocab)\n","\n","        # add a padding token with index 0\n","        self.word2idx['<pad>'] = 0\n","        \n","        # word to index mapping\n","        for index, word in enumerate(self.vocab):\n","            self.word2idx[word] = index + 1 # +1 because of pad token\n","        \n","        # index to word mapping\n","        for word, index in self.word2idx.items():\n","            self.idx2word[index] = word        "],"metadata":{"id":"5S_lploTKJbs","executionInfo":{"status":"ok","timestamp":1663396396711,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# index language using the class above\n","inp_lang = LanguageIndex(data[\"bn\"].values.tolist())\n","targ_lang = LanguageIndex(data[\"en\"].values.tolist())\n","# Vectorize the input and target languages\n","input_tensor = [[inp_lang.word2idx[s] for s in bn.split(' ')]  for bn in data[\"bn\"].values.tolist()]\n","target_tensor = [[targ_lang.word2idx[s] for s in en.split(' ')]  for en in data[\"en\"].values.tolist()]\n","\n","input_tensor[:10], target_tensor[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"01HIJxHmPtq6","executionInfo":{"status":"ok","timestamp":1663396396711,"user_tz":-360,"elapsed":4,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}},"outputId":"b82f28f4-73f3-437b-8850-5de232836a5b"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([[7, 2466, 12, 6],\n","  [7, 2480, 12, 6],\n","  [7, 2462, 12, 6],\n","  [7, 1870, 1, 6],\n","  [7, 1871, 1, 6],\n","  [7, 662, 8, 6],\n","  [7, 2162, 1, 6],\n","  [7, 126, 1, 6],\n","  [7, 2114, 1, 6],\n","  [7, 2115, 1, 6]],\n"," [[24, 703, 4, 23],\n","  [24, 703, 4, 23],\n","  [24, 703, 4, 23],\n","  [24, 1393, 1, 23],\n","  [24, 1393, 1, 23],\n","  [24, 1855, 25, 23],\n","  [24, 1898, 1, 23],\n","  [24, 629, 1, 23],\n","  [24, 784, 1, 23],\n","  [24, 784, 1, 23]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"8cwX-0rt4zmN","executionInfo":{"status":"ok","timestamp":1663396397711,"user_tz":-360,"elapsed":2,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"source":["def max_length(tensor):\n","    return max(len(t) for t in tensor)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"ycYy5gq641Uy","executionInfo":{"status":"ok","timestamp":1663396398417,"user_tz":-360,"elapsed":3,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"source":["# calculate the max_length of input and output tensor\n","max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"q05E5IwH42_1","executionInfo":{"status":"ok","timestamp":1663396398417,"user_tz":-360,"elapsed":2,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"source":["def pad_sequences(x, max_len):\n","    padded = np.zeros((max_len), dtype=np.int64)\n","    if len(x) > max_len: padded[:] = x[:max_len]\n","    else: padded[:len(x)] = x\n","    return padded"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"66dJPqzV44jd","outputId":"993b6a5d-32d0-4d38-a4c4-05df2820be41","executionInfo":{"status":"ok","timestamp":1663396401948,"user_tz":-360,"elapsed":7,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# inplace padding\n","input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]\n","target_tensor = [pad_sequences(x, max_length_tar) for x in target_tensor]\n","len(target_tensor)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4642"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"zvatfCWS46T-","outputId":"feea88d0-7ace-4d15-ac3a-2a8b9b790c13","executionInfo":{"status":"ok","timestamp":1663396401948,"user_tz":-360,"elapsed":6,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Creating training and validation sets using an 80-20 split\n","input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n","\n","# Show length\n","len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3713, 3713, 929, 929)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"IDSxA4OM5Qlp","executionInfo":{"status":"ok","timestamp":1663396402654,"user_tz":-360,"elapsed":2,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"source":["# conver the data to tensors and pass to the Dataloader \n","# to create an batch iterator\n","\n","class MyData(Dataset):\n","    def __init__(self, X, y):\n","        self.data = X\n","        self.target = y\n","        # TODO: convert this into torch code is possible\n","        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n","        \n","    def __getitem__(self, index):\n","        x = self.data[index]\n","        y = self.target[index]\n","        x_len = self.length[index]\n","        return x,y,x_len\n","    \n","    def __len__(self):\n","        return len(self.data)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3Be7lOZ5R-d","executionInfo":{"status":"ok","timestamp":1663396403470,"user_tz":-360,"elapsed":818,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 64\n","N_BATCH = BUFFER_SIZE//BATCH_SIZE\n","embedding_dim = 256\n","units = 1024\n","vocab_inp_size = len(inp_lang.word2idx)\n","vocab_tar_size = len(targ_lang.word2idx)\n","\n","train_dataset = MyData(input_tensor_train, target_tensor_train)\n","val_dataset = MyData(input_tensor_val, target_tensor_val)\n","\n","dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, drop_last=True, shuffle=True)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"blYXo7pv5TOu","executionInfo":{"status":"ok","timestamp":1663396403471,"user_tz":-360,"elapsed":4,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"source":["class Encoder(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","        super(Encoder, self).__init__()\n","        self.batch_sz = batch_sz\n","        self.enc_units = enc_units\n","        self.vocab_size = vocab_size\n","        self.embedding_dim = embedding_dim\n","        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n","        self.gru = nn.GRU(self.embedding_dim, self.enc_units)\n","        \n","    def forward(self, x, lens, device):\n","        # x: batch_size, max_length \n","        \n","        # x: batch_size, max_length, embedding_dim\n","        x = self.embedding(x) \n","                \n","        # x transformed = max_len X batch_size X embedding_dim\n","        # x = x.permute(1,0,2)\n","        x = pack_padded_sequence(x, lens) # unpad\n","    \n","        self.hidden = self.initialize_hidden_state(device)\n","        \n","        # output: max_length, batch_size, enc_units\n","        # self.hidden: 1, batch_size, enc_units\n","        output, self.hidden = self.gru(x, self.hidden) # gru returns hidden state of all timesteps as well as hidden state at last timestep\n","        \n","        # pad the sequence to the max length in the batch\n","        output, _ = pad_packed_sequence(output)\n","        \n","        return output, self.hidden\n","\n","    def initialize_hidden_state(self, device):\n","        return torch.zeros((1, self.batch_sz, self.enc_units)).to(device)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"SrsQ7dTg5V__","executionInfo":{"status":"ok","timestamp":1663396405106,"user_tz":-360,"elapsed":2,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"source":["### sort batch function to be able to use with pad_packed_sequence\n","def sort_batch(X, y, lengths):\n","    lengths, indx = lengths.sort(dim=0, descending=True)\n","    X = X[indx]\n","    y = y[indx]\n","    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"],"execution_count":20,"outputs":[]},{"cell_type":"code","source":["### Testing Encoder part\n","# TODO: put whether GPU is available or not\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","\n","encoder.to(device)\n","# obtain one sample from the data iterator\n","it = iter(dataset)\n","x, y, x_len = next(it)\n","\n","# sort the batch first to be able to use with pac_pack_sequence\n","xs, ys, lens = sort_batch(x, y, x_len)\n","\n","enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n","\n","print(enc_output.size()) # max_length, batch_size, enc_units"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UWcl4yf6SBMN","executionInfo":{"status":"ok","timestamp":1663396413507,"user_tz":-360,"elapsed":6866,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}},"outputId":"b17ba026-b886-4b35-df18-8bc4ca2e61af"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([14, 64, 1024])\n"]}]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, dec_units, enc_units, batch_sz):\n","        super(Decoder, self).__init__()\n","        self.batch_sz = batch_sz\n","        self.dec_units = dec_units\n","        self.enc_units = enc_units\n","        self.vocab_size = vocab_size\n","        self.embedding_dim = embedding_dim\n","        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n","        self.gru = nn.GRU(self.embedding_dim + self.enc_units, \n","                          self.dec_units,\n","                          batch_first=True)\n","        self.fc = nn.Linear(self.enc_units, self.vocab_size)\n","        \n","        # used for attention\n","        self.W1 = nn.Linear(self.enc_units, self.dec_units)\n","        self.W2 = nn.Linear(self.enc_units, self.dec_units)\n","        self.V = nn.Linear(self.enc_units, 1)\n","    \n","    def forward(self, x, hidden, enc_output):\n","        # enc_output original: (max_length, batch_size, enc_units)\n","        # enc_output converted == (batch_size, max_length, hidden_size)\n","        enc_output = enc_output.permute(1,0,2)\n","        # hidden shape == (batch_size, hidden size)\n","        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n","        # we are doing this to perform addition to calculate the score\n","        \n","        # hidden shape == (batch_size, hidden size)\n","        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n","        hidden_with_time_axis = hidden.permute(1, 0, 2)\n","        \n","        # score: (batch_size, max_length, hidden_size) # Bahdanaus's\n","        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n","        # It doesn't matter which FC we pick for each of the inputs\n","        score = torch.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n","        \n","        #score = torch.tanh(self.W2(hidden_with_time_axis) + self.W1(enc_output))\n","          \n","        # attention_weights shape == (batch_size, max_length, 1)\n","        # we get 1 at the last axis because we are applying score to self.V\n","        attention_weights = torch.softmax(self.V(score), dim=1)\n","        \n","        # context_vector shape after sum == (batch_size, hidden_size)\n","        context_vector = attention_weights * enc_output\n","        context_vector = torch.sum(context_vector, dim=1)\n","        \n","        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","        # takes case of the right portion of the model above (illustrated in red)\n","        x = self.embedding(x)\n","        \n","        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","        #x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","        # ? Looks like attention vector in diagram of source\n","        x = torch.cat((context_vector.unsqueeze(1), x), -1)\n","        \n","        # passing the concatenated vector to the GRU\n","        # output: (batch_size, 1, hidden_size)\n","        output, state = self.gru(x)\n","        \n","        \n","        # output shape == (batch_size * 1, hidden_size)\n","        output =  output.view(-1, output.size(2))\n","        \n","        # output shape == (batch_size * 1, vocab)\n","        x = self.fc(output)\n","        \n","        return x, state, attention_weights\n","    \n","    def initialize_hidden_state(self):\n","        return torch.zeros((1, self.batch_sz, self.dec_units))"],"metadata":{"id":"-gWqxHe9SUm4","executionInfo":{"status":"ok","timestamp":1663396414121,"user_tz":-360,"elapsed":616,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","\n","encoder.to(device)\n","# obtain one sample from the data iterator\n","it = iter(dataset)\n","x, y, x_len = next(it)\n","\n","print(\"Input: \", x.shape)\n","print(\"Output: \", y.shape)\n","\n","# sort the batch first to be able to use with pac_pack_sequence\n","xs, ys, lens = sort_batch(x, y, x_len)\n","\n","enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n","print(\"Encoder Output: \", enc_output.shape) # batch_size X max_length X enc_units\n","print(\"Encoder Hidden: \", enc_hidden.shape) # batch_size X enc_units (corresponds to the last state)\n","\n","decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n","decoder = decoder.to(device)\n","\n","#print(enc_hidden.squeeze(0).shape)\n","\n","dec_hidden = enc_hidden#.squeeze(0)\n","dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n","print(\"Decoder Input: \", dec_input.shape)\n","print(\"--------\")\n","\n","for t in range(1, y.size(1)):\n","    # enc_hidden: 1, batch_size, enc_units\n","    # output: max_length, batch_size, enc_units\n","    predictions, dec_hidden, _ = decoder(dec_input.to(device), \n","                                         dec_hidden.to(device), \n","                                         enc_output.to(device))\n","    \n","    print(\"Prediction: \", predictions.shape)\n","    print(\"Decoder Hidden: \", dec_hidden.shape)\n","    \n","    #loss += loss_function(y[:, t].to(device), predictions.to(device))\n","    \n","    dec_input = y[:, t].unsqueeze(1)\n","    print(dec_input.shape)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNziwlccSf34","executionInfo":{"status":"ok","timestamp":1663396414121,"user_tz":-360,"elapsed":2,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}},"outputId":"15d1cb29-9326-46a3-984e-b74bddb4de91"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Input:  torch.Size([64, 29])\n","Output:  torch.Size([64, 33])\n","Encoder Output:  torch.Size([12, 64, 1024])\n","Encoder Hidden:  torch.Size([1, 64, 1024])\n","Decoder Input:  torch.Size([64, 1])\n","--------\n","Prediction:  torch.Size([64, 1926])\n","Decoder Hidden:  torch.Size([1, 64, 1024])\n","torch.Size([64, 1])\n"]}]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","\n","def loss_function(real, pred):\n","    \"\"\" Only consider non-zero inputs in the loss; mask needed \"\"\"\n","    #mask = 1 - np.equal(real, 0) # assign 0 to all above 0 and 1 to all 0s\n","    #print(mask)\n","    mask = real.ge(1).type(torch.cuda.FloatTensor)\n","    \n","    loss_ = criterion(pred, real) * mask \n","    return torch.mean(loss_)"],"metadata":{"id":"WfLP2_hZSifR","executionInfo":{"status":"ok","timestamp":1663396518357,"user_tz":-360,"elapsed":609,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","## TODO: Combine the encoder and decoder into one class\n","encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n","\n","encoder.to(device)\n","decoder.to(device)\n","\n","optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)"],"metadata":{"id":"cy412nogKJFk","executionInfo":{"status":"ok","timestamp":1663396536402,"user_tz":-360,"elapsed":645,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 10\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","    \n","    encoder.train()\n","    decoder.train()\n","    \n","    total_loss = 0\n","    \n","    for (batch, (inp, targ, inp_len)) in enumerate(dataset):\n","        loss = 0\n","        \n","        xs, ys, lens = sort_batch(inp, targ, inp_len)\n","        enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n","        dec_hidden = enc_hidden\n","        \n","        # use teacher forcing - feeding the target as the next input (via dec_input)\n","        dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n","        \n","        # run code below for every timestep in the ys batch\n","        for t in range(1, ys.size(1)):\n","            predictions, dec_hidden, _ = decoder(dec_input.to(device), \n","                                         dec_hidden.to(device), \n","                                         enc_output.to(device))\n","            loss += loss_function(ys[:, t].to(device), predictions.to(device))\n","            #loss += loss_\n","            dec_input = ys[:, t].unsqueeze(1)\n","            \n","        \n","        batch_loss = (loss / int(ys.size(1)))\n","        total_loss += batch_loss\n","        \n","        optimizer.zero_grad()\n","        \n","        loss.backward()\n","\n","        ### UPDATE MODEL PARAMETERS\n","        optimizer.step()\n","        \n","        if batch % 100 == 0:\n","            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.detach().item()))\n","        \n","        \n","    ### TODO: Save checkpoint for model\n","    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / N_BATCH))\n","    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tj3Oi73sKNgC","executionInfo":{"status":"ok","timestamp":1663396715184,"user_tz":-360,"elapsed":86349,"user":{"displayName":"Abu Ubaida Akash","userId":"06212671143808032482"}},"outputId":"9f655366-f15d-43ab-f68b-f10a61541161"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 0 Loss 1.5364\n","Epoch 1 Loss 0.7659\n","Time taken for 1 epoch 8.800162315368652 sec\n","\n","Epoch 2 Batch 0 Loss 0.5851\n","Epoch 2 Loss 0.5081\n","Time taken for 1 epoch 8.369094848632812 sec\n","\n","Epoch 3 Batch 0 Loss 0.3871\n","Epoch 3 Loss 0.3484\n","Time taken for 1 epoch 8.455190658569336 sec\n","\n","Epoch 4 Batch 0 Loss 0.2543\n","Epoch 4 Loss 0.2222\n","Time taken for 1 epoch 8.492425441741943 sec\n","\n","Epoch 5 Batch 0 Loss 0.1216\n","Epoch 5 Loss 0.1310\n","Time taken for 1 epoch 8.567250490188599 sec\n","\n","Epoch 6 Batch 0 Loss 0.0909\n","Epoch 6 Loss 0.0767\n","Time taken for 1 epoch 9.066980361938477 sec\n","\n","Epoch 7 Batch 0 Loss 0.0551\n","Epoch 7 Loss 0.0491\n","Time taken for 1 epoch 8.680059671401978 sec\n","\n","Epoch 8 Batch 0 Loss 0.0345\n","Epoch 8 Loss 0.0344\n","Time taken for 1 epoch 8.687597513198853 sec\n","\n","Epoch 9 Batch 0 Loss 0.0292\n","Epoch 9 Loss 0.0263\n","Time taken for 1 epoch 8.637736797332764 sec\n","\n","Epoch 10 Batch 0 Loss 0.0137\n","Epoch 10 Loss 0.0203\n","Time taken for 1 epoch 8.636646509170532 sec\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"qpNYGd9iKkKh"},"execution_count":null,"outputs":[]}]}